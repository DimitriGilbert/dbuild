1:"$Sreact.fragment"
2:I[22304,["271","static/chunks/271-6613a09017b67af4.js","442","static/chunks/442-5f28b56b616ff3ca.js","177","static/chunks/app/layout-267ae1d5e4eb94a7.js"],"ThemeProvider"]
3:I[71000,["271","static/chunks/271-6613a09017b67af4.js","442","static/chunks/442-5f28b56b616ff3ca.js","177","static/chunks/app/layout-267ae1d5e4eb94a7.js"],"FloatingNavigation"]
4:I[13842,[],""]
5:I[86880,[],""]
7:I[25803,[],"OutletBoundary"]
9:I[25803,[],"MetadataBoundary"]
b:I[25803,[],"ViewportBoundary"]
d:I[16773,[],""]
:HL["/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/9579c992d89962c7.css","style"]
0:{"P":null,"b":"fxCbDsEksO5NPvyXbZAu_","p":"","c":["","blog","tags","server",""],"i":false,"f":[[["",{"children":["blog",{"children":["tags",{"children":[["tag","server","d"],{"children":["__PAGE__",{}]}]}]}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/9579c992d89962c7.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":[["$","head",null,{"children":["$","script",null,{"src":"https://cdn.counter.dev/script.js","data-id":"154c6878-7558-4eff-90f9-bd4904015df1","data-utcoffset":"1","async":true}]}],["$","body",null,{"className":"__className_f367f3","children":["$","$L2",null,{"attribute":"class","defaultTheme":"dark","enableSystem":true,"disableTransitionOnChange":true,"children":[["$","$L3",null,{}],["$","main",null,{"children":["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}]}]]}]]}],{"children":["blog",["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["tags",["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","tags","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":[["tag","server","d"],["$","$1","c",{"children":[null,["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children","blog","children","tags","children","$0:f:0:1:2:children:2:children:2:children:0","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","forbidden":"$undefined","unauthorized":"$undefined"}]]}],{"children":["__PAGE__",["$","$1","c",{"children":["$L6",null,["$","$L7",null,{"children":"$L8"}]]}],{},null,false]},null,false]},null,false]},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","-uBqZRO7gPMNMzZRD6HDU",{"children":[["$","$L9",null,{"children":"$La"}],["$","$Lb",null,{"children":"$Lc"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$d","$undefined"],"s":false,"S":true}
e:I[73104,["271","static/chunks/271-6613a09017b67af4.js","442","static/chunks/442-5f28b56b616ff3ca.js","792","static/chunks/app/blog/tags/%5Btag%5D/page-aeecd19139ff1a04.js"],"TagDetailContent"]
f:T11ee,
Hello everyone, I‚Äôd like to introduce LiteChat, a project I created.

[Repository](https://github.com/DimitriGilbert/LiteChat) and download link [here](https://github.com/DimitriGilbert/LiteChat/releases) (available in French, English, Spanish, Italian, and German).

LiteChat is an AI chat application I built to interact with both local and remote LLMs‚Äîall within your browser. It‚Äôs designed with a "local-first" philosophy, requiring only an HTTP server to run, with everything else handled in your browser! No tracking, no accounts‚Äîyou bring your own API keys. Data is saved in an IndexedDB database, and you can synchronize your conversations using Git.

Yes, entirely in the browser! üòõ To make this work, I also implemented a virtual file system (again, all in the browser). You can clone repos and include files from the VFS in your conversations! But manually selecting files was tedious, so I integrated tools for managing the VFS and Git.

With the core architecture in place, I added support for HTTP MCP servers. However, standard stdio servers were still missing, so I also built a bridge (rewritten by AI from `mcp-proxy`) to make them work (you can deploy it anywhere, but it‚Äôs not secure!).

Sure, AI is fun, but I was getting tired of text-only interactions. So, I added support for Mermaid diagrams and HTML forms (now you don‚Äôt even need to think about how to phrase your requests!). Sure, Mermaid diagrams aren‚Äôt the prettiest, but since I added a workflow module with visualizations based on [reactflow.dev](https://reactflow.dev), I also included a way for LLMs to generate them! And since plain text isn‚Äôt very engaging, there‚Äôs also a "Beat" block that uses [strudel.cc](http://strudel.cc/) to add auditory feedback.

Testing was getting repetitive, so I created a prompt library with templates‚Äînow you just fill in a form! (Okay, maybe I also needed it for workflows‚Ä¶)

What‚Äôs an Agent, you ask? It‚Äôs a system prompt, tools, and task-specific prompts! So, you also get a library for those.

Prompts and agents can integrate into workflows (that‚Äôs what they‚Äôre designed for!), but you also have transformation steps, user code execution, and custom prompts to facilitate transitions.

As you might have guessed, if I have a way to execute code in workflows, why not run AI-generated code? Yes, you can! In Python or JavaScript. And if you‚Äôre feeling adventurous, you can run JavaScript in "unsafe" mode (`eval` and all‚Äîthat‚Äôs code for "yolo" üòÜ). This can produce cool stuff, like [this one-shot Three.js scroll shooter](https://dimitrigilbert.github.io/racebench/scroller/index.html). You can export it in one click (the template is a bit ugly, but I‚Äôll improve it!).

To avoid losing context, all these UI blocks can be "activated" (or rather, suggested) using rules. Of course, you can add your own rules! There‚Äôs even a button to ask the AI to pick the best ones for your current prompt.

You also get the usual regenerate (with a different model if you like) and forking options. You can even edit responses manually to remove unnecessary parts. Code blocks are also editable with syntax highlighting for common languages (but no autocompletion or fancy features‚Äîlet‚Äôs not push grandma into the bushes!).

To top it all off, you can organize AI "races" with an unlimited number of participants (though that depends on your budget, haha). It‚Äôs great for benchmarking or seeing which model will replace us first. I even built a small tool that takes exported race conversations and turns them into a benchmark site (currently more focused on the JS execution block: [https://dimitrigilbert.github.io/racebench/scroller/index.html](https://dimitrigilbert.github.io/racebench/scroller/index.html) for the "game" mentioned earlier).

I‚Äôm sure I forgot a few things, but you‚Äôve got the gist! üòä

The hosted version is on GitHub Pages, with no tracking and no accounts! You bring your own API keys. You probably won‚Äôt be able to use the hosted version for your local LLM due to HTTPS/HTTP restrictions, but as I said, you can [download it](https://github.com/DimitriGilbert/LiteChat/releases) and host it with a simple HTTP server. There are also localized versions for French, Italian, German, and Spanish. A short (and incomplete) tutorial playlist if you‚Äôre feeling lost: [https://www.youtube.com/playlist?list=PL5Doe56gCsNRdNyfetOYPQw_JkPHO3XVh](https://www.youtube.com/playlist?list=PL5Doe56gCsNRdNyfetOYPQw_JkPHO3XVh)

I hope you enjoy it, and constructive feedback is greatly appreciated! üòä

---
10:T156f,
Salut a tous, pour mon premier post, je vous presente LiteChat dont je sui le cr√©ateur.

[Repo](https://github.com/DimitriGilbert/LiteChat) et ici [pour t√©l√©charger](https://github.com/DimitriGilbert/LiteChat/releases) (en francais, anglais, espagnol, italien et allemand).



C‚Äôest un chat IA que j‚Äôai cr√©√© pour pouvoir utiliser des LLM locaux et distant, le tout dans votre navigateur. Il est con√ßu pour √™tre ‚Äúlocal first‚Äù et n‚Äôa besoin que d‚Äôun serveur HTTP pour fonctionner, tout le reste c‚Äôest dans votre navigateur ! Pas de tracking, pas de compte, vous venez avec vos cl√© d‚ÄôAPI ! Les donn√©es sont sauvegard√©es dans une base de donn√©es IndexeDB et vous pouvez synchroniser vos conversations en utilisant git.

Oui, dans le navigateur :P Pour ce faire, j‚Äôai aussi d√ª impl√©menter un syst√®me de fichiers virtuel (oui, toujour dans le navigateur en utilisant ). Vous avez donc acc√®s aux deux, tant qu‚Äôa faire ! Vous pouvez cloner un repo et joindre des fichiers du VFS dans vos conversations !

Mais comme la s√©lection manuelle des fichiers, c‚Äô√©tait une corv√©e, j‚Äôai int√©gr√© des outils pour le VFS et git !

Ensuite, comme l‚Äôarchitecture de base √©tait l√†, et bien j‚Äôai ajout√© le support des serveurs MCP HTTP, mais il manquait toujours les serveurs stdio ‚Ä¶, donc j‚Äôai aussi ‚Äúfait‚Äù un bridge (r√©√©crit par l‚ÄôIA √† partir de mcp-proxy ) pour les utiliser (vous pouvez le d√©ployer o√π vous voulez mais ce n‚Äôest pas s√©curis√© !)

Apres, c‚Äôest bien mignon l‚ÄôIA, mais j‚Äôen avais un peu marre du texte seul, du coup, j‚Äôai ajout√© le support des diagrammes Mermaid et des formulaires HTML (Comme ca on a meme plus besoin de r√©fl√©chir a quoi lui dire a la machine !). Bon‚Ä¶ apr√®s‚Ä¶les diagrammes Mermaid c‚Äôest un peu moche, et comme j‚Äôai ajout√© un module de workflow avec des visualisations bas√©e sur [https://reactflow.dev/], j‚Äôai aussi ajout√© un moyen pour les LLM de vous en cr√©er ! Et puis comme le text ca fait pas beaucoup de bruit, il y a aussi in block ‚ÄúBeat‚Äù qui utilise (http://strudel.cc/) pour aussi en profiter de maniere auditive !

Et puis bon, en testant, toujours taper les m√™mes prompts avec juste quelques diff√©rences c‚Äô√©tait lourd aussi, j‚Äôai donc fait un module de biblioth√®que de prompts avec des mod√®les pour qu‚Äôy ai plus qu‚Äôa remplir un formulaire ;) (peut etre aussi que j‚Äôen avais besoin pour les workflows‚Ä¶)

‚ÄòPis, un Agents, c‚Äôest quoi ? hein ? bah un prompt syst√®me, des outils et des prompts sp√©cifiques pour les t√¢ches ! Donc √ßa aussi vous en avez une librairie !

Les prompts et les agents peuvent s‚Äôint√©grer dans les workflows (duh, ils √©taient faits pour √ßa !) mais vous avez aussi des √©tapes de ‚Äútransformation‚Äù/ex√©cution de code utilisateur/‚Äúprompt personnalis√©‚Äù pour faciliter le transit !

Comme vous l‚Äôavez peut-√™tre devin√©, si j‚Äôai une forme d‚Äôex√©cution de code pour les workflows, Est ce que je pourrais t‚Äôy donc pas faire tourner le code g√©n√©r√© par l‚ÄôIA, hein ? Eeeeh bha SI ! En Python ou JavaScript Et m√™me que si vous √™te un dinguo, vous pouvez faire tourner le js en mode ‚Äúunsafe‚Äù (eval et yolo XD) du coup ca peut produire des trucs (comme ce one shot threejs scroll shooter ) que vous pouvez exporter en 1 clic (le template est moche mais je vais y travailler !)

Afin de n‚Äôpas completement obliterer le context, tous ces jolis blocs d‚ÄôUI peuvent √™tre ‚Äúactiv√©s‚Äù (plut√¥t sugg√©r√©s ^^) en utilisant des r√®gles. Evidement, vous pouvez ajouter vos r√®gles a vous ! Et meme que vous avez un bouton pour demander a l‚ÄôIA de les choisir pour vous pour votre prompt actuel !

Bien s√ªr, vous avez les habituels regen (avec un mod√®le diff√©rent si le coeur vous en dis) et forking, mais vous pouvez aussi modifier une r√©ponse a la main pour d√©gager l‚Äôinutile. D‚Äôailleur, Les blocs de code sont aussi modifiable avec la coloration syntaxique pour les langages les plus courants, (mais pas d‚Äôauto-compl√©tion ou autre truc de bogoss, on va pas poussez m√©m√© dans les orties !).

Pour couronner le tout, vous pouvez organiser des courses d‚ÄôIA avec un nombre illimit√© de participants (ca dependra de la profondeur de votre portefeuille :P). C‚Äôest cool pour faire des benchmarks ou quand on veut voir laquelle des machines prendra notre place en premier‚Ä¶ J‚Äôai m√™me fait un petit outil qui prend une conversation de course export√©e et qui cr√©e un mini site de benchmark (plus cibl√© sur le bloc d‚Äôex√©cution JS pour l‚Äôinstant https://dimitrigilbert.github.io/racebench/scroller/index.html pour le ‚Äújeu‚Äù d‚Äôavant)

J‚Äôoublie certainement quelques bricoles, mais vous avez compris l‚Äôessentiel ^^

La version h√©berg√©e est sur les pages GitHub et il n‚Äôy a pas de tracking, pas de compte ! Vous apportez vos propres cl√©s API ! Vous ne pourrez probablement pas utiliser la version h√©berg√©e pour votre LLM local √† cause des restrictions https/http, mais comme je l‚Äôai dit, vous pouvez t√©l√©charger https://github.com/DimitriGilbert/LiteChat/releases et h√©berger avec un simple serveur HTTP. Vous avez m√™me des versions localis√©es pour le fran√ßais, l‚Äôitalien, l‚Äôallemand et l‚Äôespagnol. Une petite playlist (tr√®s incompl√®te) de tutoriels si vous vous sentez un peu perdu https://www.youtube.com/playlist?list=PL5Doe56gCsNRdNyfetOYPQw_JkPHO3XVh

J‚Äôesp√®re que vous appr√©cierez et les commentaires constructifs sont grandement appr√©ci√©s :D6:["$","$Le",null,{"tag":"server","posts":[{"slug":"projects-litechat-litechat-a-local-first-and-self-hostable-ai-chat-app-for-power-user","title":"LiteChat - A local first and self hostable AI chat app for power user","description":"A smallish presentation of my project LiteChat !","date":"$D2025-07-04T10:40:17.000Z","category":"General","tags":["ai","chat","local","server"],"content":"$f","readTime":4,"toc":[],"directory":"Projects/LiteChat/LiteChat : A local first and self hostable AI chat app for power user","relativePath":"Projects/LiteChat/LiteChat : A local first and self hostable AI chat app for power user/index.md","filePath":"/home/didi/workspace/Code/dbuild.io/apps/web/content/blog/Projects/LiteChat/LiteChat : A local first and self hostable AI chat app for power user/index.md","isCategory":false},{"slug":"projects-litechat-litechat-un-chat-ia-local-first-auto-hebergeable-sur-un-server-http","title":"LiteChat - Un chat IA local first, auto hebergeable sur un server HTTP","description":"Une petite pr√©sentation de mon projet LiteChat, en Fran√ßais dans le texte !","date":"$D2025-07-04T10:39:17.000Z","category":"General","tags":["ai","chat","local","server"],"content":"$10","readTime":5,"toc":[],"directory":"Projects/LiteChat/LiteChat : Un chat IA local first, auto hebergeable sur un server HTTP","relativePath":"Projects/LiteChat/LiteChat : Un chat IA local first, auto hebergeable sur un server HTTP/index.md","filePath":"/home/didi/workspace/Code/dbuild.io/apps/web/content/blog/Projects/LiteChat/LiteChat : Un chat IA local first, auto hebergeable sur un server HTTP/index.md","isCategory":false}]}]
c:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
a:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Dbuild.dev"}],["$","meta","2",{"name":"description","content":"Dbuild.dev is a portfolio and blog showcasing projects and insights"}],["$","link","3",{"rel":"manifest","href":"/manifest.webmanifest","crossOrigin":"$undefined"}],["$","meta","4",{"name":"robots","content":"index, follow"}],["$","meta","5",{"name":"googlebot","content":"index, follow"}],["$","meta","6",{"property":"og:title","content":"Dbuild.dev"}],["$","meta","7",{"property":"og:description","content":"Dbuild.dev is a portfolio and blog showcasing projects and insights"}],["$","meta","8",{"property":"og:url","content":"https://dbuild.dev/"}],["$","meta","9",{"property":"og:site_name","content":"Dbuild.dev"}],["$","meta","10",{"property":"og:locale","content":"en_US"}],["$","meta","11",{"property":"og:image","content":"https://dbuild.dev/og-image.jpg"}],["$","meta","12",{"property":"og:image:width","content":"1200"}],["$","meta","13",{"property":"og:image:height","content":"630"}],["$","meta","14",{"property":"og:image:alt","content":"Dbuild.dev - Portfolio and Blog"}],["$","meta","15",{"property":"og:type","content":"website"}],["$","meta","16",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","17",{"name":"twitter:title","content":"Dbuild.dev"}],["$","meta","18",{"name":"twitter:description","content":"Dbuild.dev is a portfolio and blog showcasing projects and insights"}],["$","meta","19",{"name":"twitter:image","content":"https://dbuild.dev/og-image.jpg"}],["$","link","20",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"32x32"}]]
8:null

1:"$Sreact.fragment"
2:I[22304,["239","static/chunks/239-c47e640cea1e8478.js","802","static/chunks/802-cb271f7d125031e5.js","177","static/chunks/app/layout-8f6931abe4e72e4f.js"],"ThemeProvider"]
3:I[71000,["239","static/chunks/239-c47e640cea1e8478.js","802","static/chunks/802-cb271f7d125031e5.js","177","static/chunks/app/layout-8f6931abe4e72e4f.js"],"FloatingNavigation"]
4:I[13842,[],""]
5:I[86880,[],""]
6:I[31494,["239","static/chunks/239-c47e640cea1e8478.js","802","static/chunks/802-cb271f7d125031e5.js","608","static/chunks/608-2b691ad71583a2ff.js","974","static/chunks/app/page-574755981f841de1.js"],"HomePageContent"]
d:I[25803,[],"OutletBoundary"]
f:I[25803,[],"MetadataBoundary"]
11:I[25803,[],"ViewportBoundary"]
13:I[16773,[],""]
:HL["/_next/static/media/e4af272ccee01ff0-s.p.woff2","font",{"crossOrigin":"","type":"font/woff2"}]
:HL["/_next/static/css/50152c3edddaf6a5.css","style"]
7:T45e9,
_TLDR; Eric loop is a concept that upgrades Ralph loop by adding more complexity and depth to the idea of managing AI systems, [bash version of the article](/assets/blackhole/from_ralph_to_eric/bashticle.sh)_

I wont reintroduce the concept of Ralph loop, if you have been anywhere near AI in the first half of January 2026, you have heard of it ! If not, you should go and watch [Theo's video](https://www.youtube.com/watch?v=Yr9O6KFwbW4) (or someone else's but this is a good !)

You probably know which comics character Ralph is refering to, but Eric... who could it possibly be ?

If you thought short, fat and angry, you'd be right ! I'm of course talking about Eric Cartman from South Park !

While Ralph is naive and innocent, Eric is calculating and manipulative. Not something I'd look for in a Human, but for managing a bunch of AIs ? HELL YEAH !

![Eric saw Ralph](/images/blog/blackhole/from_ralph_to_eric/Eric_saw_Ralph.webp)

## The Eric Loop

An idea, even if good, always need some work and some back and forth to be implemented. So we first expose the idea to the AI to get an requirement document (PRD) and we work on it !

How ? you'll need to read first ! and straight away update parts you don't agree with or things you need to be more thorough !

Once that is done, ask AI models to ask You questions about the PRD and give all those, the PRD and your replies to another AI for update

Rince, Repeat, until you are satisfied with the document.

You can even get multiple model go at it to then compare and merge the outputs, using AI, of course :D

This is where we start diverging from the basic Ralph loop. instead of just passing that to the AI and hoping tasks will be implemented properly we get an AI to pre split and formalise the tasks and sub tasks into a list !

The rift grows further as we split the task implementation in several steps with:
* a planning phase that analyzes the requirements for the tasks, existing code, and conduct the needed research
* an execution phase to do the actual work,
* an optional automated verification phase (check types, build, tests, ...) with automated feedback to the execution phase in case of errors,
* an result review phase, that can send back to the execution phase for further refinement.

Once all that is done ? the Eric loop goes on for the next phase of the plan, just like Ralph !

## But, Why... ?

Separation of concerns !

Yes models have gotten smarter, but if you played around with sub agents and skills, you know that prompting is not dead (yet...)

Having a neat separation like that helps you have better prompts for each phase of the task execution.

As a side effect, it mmeans you can control which model is used for which phase maybe you dont need Opus the whole way if it made a banger plan !

## What would it look like ?

We are going to create a small project from an idea I have, you can do it to if you like !

It's called Tiny-till, a small app to have a simple till for itinerant merchants.

But we are going to need a tool to help us ... 

### Task-o-matic

Yep, I already kind of made said tool :D ! [task-o-matic](https://task-o-matic.dev)

I'll write more about it in a future post ! but you already have plenty of content to go through on the site itself.

I made sure to generate a lot of docs and a couple tutorials so you can already give it a try if you'd like !

But in a nutshell, it helps you create PRDs, refine them , split into tasks and subtasks and finally wiring all that to your favorite AI harness !

### Let's get this rolling

For the AI to operate properly, we need a specific stack, that way, we limit hallucination !

#### Initialisation and bootstrapping

Task-o-matic uses (https://better-t-stack.dev) under the hood to bootstrap the stack so let's do that !

```bash
npx task-o-matic@latest init init --project-name tiny-till \
  --frontend tanstack-router \
  --backend none \
  --package-manager bun && cd tiny-till
```

Boom, a monorepo for Tiny-till ! Batteries included : tailwind, shadcn, build script and all :D

Why `init init` ? you might have missed the whole using AI to code whole projects, sometimes... it is not aesthetically pleasing, and you should learn not to care to much (is my take on that... or lazyness...)

You will need a .env file to configure the AI stack.

```ini
AI_PROVIDER=openrouter

AI_MODEL=nvidia/nemotron-3-nano-30b-a3b:free

OPENROUTER_API_KEY=sk_123456azertPOIUY7890i58008
```

#### Document the requirements of your project

Now, we tell the AI what we want to do, but why would we limit ourselves to 1 ?

```bash
npx task-o-matic@latest prd create \
  --ai-reasoning 4096 \
  --stream \
  --ai "xiaomi/mimo-v2-flash:free;reasoning=4096" \
  --ai "mistralai/devstral-2512:free:free" \
  --ai "nvidia/nemotron-3-nano-30b-a3b:free;reasoning=4096" \
  --ai "minimax/minimax-m2.1;reasoning=4096" \
  --ai "z-ai/glm-4.7;reasoning=4096" \
  --ai "google/gemini-3-flash-preview;reasoning=4096" \
  --combine-ai "z-ai/glm-4.7;reasoning=4096" \
  "i would like to build tiny-till,
  it will be a small web app, local first (for sparse internet connection) that serve as a very simple till for on the go seller, farmers markets stall, etc...
  the idea came from me watching my baker who does delivery tour twice a week. she is always fighting here calculator to make the tally and she gromle about it a lot
  the idea wwould be only a few screens : 
  - product management (add/remove product, name+price (img optional) ) : a list with action buttons, + or edit happen inline (+ at the top)
  - a tally page : grid of product for fast and easy access (row of 2 or 3 for mobile, 4 to 6 on tablet, normal/compact variant, control by setting)
    - clicking on a product adds it to the count
    - number of this product added appear in the card, click on it trigger an input field to enter value with a remove button
  - a setting page : theme, display, import/export catalog
  No saving, it is purely done too calculate the price and is not meant for accounting purposes
  i am using tanstack-router and the project is already set up with tailwind css typescript and shadcnUI"
```

Am I using free endpoints for "real" work ? Yes, yes I am ! Does it distort my views on how much AI work should cost ? ... Why would it ? No, no, you just being a killjoy right now !

#### Petrol is not the only thing that needs refining !

A few minutes later... I got myself this (`cat .task-o-matic/prd/prd-master.md`)[/assets/blackhole/from-ralph-to-eric/prd-master.md] it doesn't really need more questions, but let's see what Claude has to say, shall we ?

```bash
npx task-o-matic@latest prd question  --stream \
  --file .task-o-matic/prd/prd-master.md \
  --ai-model anthropic/claude-4.5-sonnet --ai-reasoning 1500
```

Well, let's answer those... some are pertinant ! I guess that's why we bring out the big guns !

Let's reply !

```bash
npx task-o-matic@latest prd refine  --stream\
  --file .task-o-matic/prd/prd-master.md \
  --ai-model anthropic/claude-4.5-sonnet --ai-reasoning 1500 \
  --output .task-o-matic/prd/prd-master-refined.md \
  --questions prd-questions.json
```

Questions are asked interactivelly ;)

```markdown
"The PRD mentions using Zustand with persist middleware for the Catalog, but also specifies IndexedDB as the storage layer. Should Zustand's persist middleware be configured to use IndexedDB directly, or will there be a custom sync layer between Zustand and IndexedDB? This affects how image blobs are handled since Zustand persist middleware typically works best with serializable data."

yes, configure Zustand's persist middleware to use IndexedDB directly.
```

```markdown
"For the 'Tap Badge to manually enter quantity' feature, what should happen if a user enters invalid input (negative numbers, decimals, non-numeric characters, or zero)? Should zero be treated as 'remove from cart' or should it maintain the item with 0 quantity until explicitly removed?",

zero should be treated as 'remove from cart'.
```

```markdown
"The PRD states the tally is 'transient' and held in memory, yet also mentions using sessionStorage. Given that sessionStorage persists across page refreshes within the same tab, this conflicts with the 'privacy and simplicity' goal of resetting on refresh. Should the tally truly reset on refresh (pure memory), or should it survive accidental refreshes during a transaction (sessionStorage)?",

no persistance, this is not for accounting and should only be in memory, when a new tally starts, the previous one does not exist anymore.
```

```markdown
"With TanStack Router's file-based routing, how should the navigation structure be organized? Specifically, should the Tally Page be the root route ('/'), and if users are on the Settings or Catalog management page when they refresh, should they be automatically redirected back to the Tally Page to prevent data loss confusion?",

yes, / is the tally page, yes redirect to tally page.
```

```markdown
"The image upload feature is marked as 'optional' for products, but the PRD recommends 'no images for MVP' in the risk mitigation. Should image upload functionality be completely excluded from MVP (Phase 1-5), or should the data model and UI be built to accommodate images even if the upload feature is disabled/hidden initially?",

no, i want images, just inforce a strict size limitation, 128*128 px, this is not meant to be a full image gallery, just a thumbnail for display, future improvement maybe to try and resize/optimise bigger image directly on device...but not in MVP !
```

```markdown
"For the Import/Export catalog feature, what should happen when importing a JSON file that contains product IDs that conflict with existing products? Should it merge (overwrite matching IDs), append (create duplicates), or prompt the user to choose? Also, should the import validate the JSON schema and handle corrupt/invalid files gracefully?",

overwrite and yes, must validate.
```

```markdown
"The 'Compact vs Normal' view toggle affects card size, but how should this interact with the responsive column count? For example, if a tablet user sets 6 columns in Normal view, should switching to Compact view automatically increase columns (e.g., to 8) to utilize the space savings, or should column count remain fixed per the user's explicit setting?",

yes, auto increase, 'tis why we want compact !
```

```markdown
"Given the Turborepo setup mentioned in the stack, is this application intended to be part of a monorepo with potential future packages (e.g., a companion admin dashboard, analytics service)? If so, should the data models and storage utilities be architected in a shared package from the start, or is this truly a standalone application for now?"

no, single package for now, we'll see later for the rest. let's keep it simple for now.
```

Well, this little stunt just costed me a nice 15 cts, more or les 10x more than the first PRD generation...

I don't know what is the most amazing... that 

* 1 call costs more than the 10 previous, 
* I can complain about a 2 days worth of work document cost 15 cents for only a few seconds of work !
* a document worth 2 of my days of work costs 15 cents to produce...in only a few seconds...

I haven't decided yet...anywooooooo, time to move on and not get siderated !

#### Touching up and go

When i said seconds, i lied, I spent 5 minutes editing the file. to fix lib versions, marked install and config work as done, and, finally, set expectation for the design.

the last thing we have to do, is ask an AI to split into main tasks.

once again, i wont only do 1, but this time, I'll ask Claude to be the final task creator, from others input !

```bash
npx task-o-matic@latest prd parse  --ai-reasoning 4096 --stream \
  --ai "xiaomi/mimo-v2-flash:free;reasoning=4096"\
  --ai "nvidia/nemotron-3-nano-30b-a3b:free;reasoning=4096" \
  --ai "z-ai/glm-4.7;reasoning=4096" \
  --combine-ai "anthropic/claude-4.5-sonnet;reasoning=4096"
```

And there goes another 8.2 cents burnt for the token Gods, but in return, we get a detailed breakdown of the tasks required to complete the project !

We still have to split those tasks though... To make them more palatable for the current crop of AI models ! 

You should really consider reviewing the tasks in detail before spliting, not vibe planning like a muppet ! (guess what I did ^^)

```bash
npx task-o-matic@latest tasks split  --all --stream \
  --reasoning 4096 \
  --ai "xiaomi/mimo-v2-flash:free;reasoning=4096"\
  --ai "nvidia/nemotron-3-nano-30b-a3b:free;reasoning=4096" \
  --ai "z-ai/glm-4.7;reasoning=4096" \
  --combine-ai "anthropic/claude-4.5-sonnet;reasoning=4096"
```

I think Claude is not necessary here, but I had me $3 of openrouter credit i have to burn before the end of the month soooooo... big guns it is !

Burnt a tenth of that ! but now... we are actually ready ! Almost...

#### AGENTS.md

Or CLAUDE, or GEMINI, depends on your harness of choice, For me, it is opencode i'am going to run the /init prompt in opencode !

```bash
opencode run "/init"
```

it is not mandatory, but it is a good way to prevent dumb mistake and set some proper behavior regarding a few things, for me, i'll add the following

* Not to run the dev server
* not start background/long running processes
* not to use `:any`, `as any` or `any` as type, I want a typesafe codebase
* before claiming success, `bun run check-types` and `bun run build` must both succeed
* to fix LSP error when they happen
* use shadcn component has much as possible
* stay DRY and prefer creating custom components and utilities than repeat code
* use adapted skills when possible (frontend-design skill is mandatory when working on the frontend)
* that it is a static app project that will be hosted on github pages
* to use Context7 MCP in case more documentation or up to date documentation is needed (as the knowledge is certainly behind because of cutoff training date)

```bash
opencode run "Add the following to the AGENTS.md, remove any conflicting instructions you created, these take precedence : 
* Not to run the dev server
* not start background/long running processes
* not to use `:any`, `as any` or `any` as type, I want a typesafe codebase
* before claiming success, `bun run check-types` and `bun run build` must both succeed
* to fix LSP error when they happen
* use shadcn component has much as possible
* stay DRY and prefer creating custom components and utilities than repeat code
* use adapted skills when possible (frontend-design skill is mandatory when working on the frontend)
* that it is a static app project that will be hosted on github pages
* to use Context7 MCP in case more documentation or up to date documentation is needed (as the knowledge is certainly behind because of cutoff training date)" -c
```

I might add more as the agent works if i see reccuring errors and dumb things happening

#### Time to let Eric loose...

Well, guys, stash your parents away cause we are going to let Eric go at it !

Because I am El CheapoDev DelBrokeCasa, i am going to use my GLM coding plan to code, that way, i wont break the bank and it is OK enough for something like that i think !

If you'd rather use claude code, use the `--tool claude` option. (or codex/gemini/kilo) but opencode is nicer as it stream the content out (in part at least) so you see what is happening !

```bash
npx task-o-matic@latest tasks execute-loop --include-prd \
  --plan --plan-model zai-coding-plan/glm-4.7 \
  --review --review-model zai-coding-plan/glm-4.7 \
  --model zai-coding-plan/glm-4.7 \
  --validate "npm run check-types && npm run build"
```

And now, you wait, coffee, snacks, more coffee, diner and breakfast probably, it gonna take a while ^^

### What's the result

Half a day later, Eric has successfully completed the task. yaaay \o/

`npm run dev`, browser to http://localhost:3001 aaaaand, it does not work.... XD

I have a very fancy error page telling me about some kind of "exceeded depth error blablabla"... Zustand... i bloody fucking HATE Zustand !

I could have gone in, open the project, read some of the 35970 lines of... **35970 LINES OF CODE** ??? Naaah, dude, ain't no way i'm even thinking about that !

Of course, i asked GLM to fix this obviously terrible usage of Zustand, and I even have to spend another few minutes screaming about some redirection to the / issue... I still felt like a caveman though !

I mean, having to open a tool ? To do ... **work** ?? Like it's 2022 or something !

I haven't been testing anything yet, so i'm pretty sure there'll be a few more issues, but the dev server runs, i can navigate the app without error (even in console) so it is not bad at all !

I might do a follow up later on, to update you on what i had to do to get it a bit closer to the original idea (if needed ^^)

## What do you think ? Where do we go from here ?

So that's the end (of this article) ! What do you think ? did you try a similar technique ? What's the plan next, cause...

If you are interested, the repo can be found on [github](https://github.com/DimitriGilbert/tiny-till). Is the code great ?

As for [task-o-matic](https://task-o-matic.dev), the [repo is on github](https://github.com/DimitriGilbert/task-o-matic) so feel free to poke around ;)

What about the "Eric Loop", how can you do that yourself ? Well, the beautiful thing with AI is that, you can actually ask it to write code ! So a quick

```markdown
coudl you create a bash script to have a program that would run the "Eric Loop" with custom options ?

letting me specify the project, what model to use and when, I basically want everything configurable through options !

use the --help command of task-o-matic if you need any doc !
```

[this being the result](/assets/blackhole/from_ralph_to_eric/eric_loop.sh), your own Eric Loop, ain't life beautiful ?

Hope you enjoyed, I'll see you around
8:T4c64,
Je vais pas re-introduire le concept de Ralph loop, si vous avez été a côté de l'IA dans la première moitié de janvier 2026, vous en avez entendu parler ! Si non, vous devriez aller voir la vidéo de [Theo]((https://www.youtube.com/watch?v=Yr9O6KFwbW4)) (ou quelqu'un d'autre mais celle-la est bonne !)

Vous savez probablement quel personnage de comics Ralph référence, mais Eric... ca pourrait être qui ?

Si vous avez pensé petit, gros et en colère, vous avez raison ! Je parle bien sûr d'Eric Cartman de South Park !

Alors que Ralph est naïf et innocent, Eric est calculateur et manipulateur. Pas quelque chose que je chercherais chez une personne, mais pour gérer un tas d'IA ? Carrément !

![Eric saw Ralph](/images/blog/blackhole/from_ralph_to_eric/Eric_saw_Ralph.webp)

## La boucle Eric

Comme chaque projet ca commence par une idée, 

Et même si elle est bonne, on a toujours besoin de la retravailler, de faire des ajustements, ... pour bien implémentée.

Donc on expose d'abord l'idée à l'IA pour avoir un Product Requirements Document (PRD) et on travaille dessus !

Comment ca, lire ? Et bhe oui, il faut d'abord lire ! et tout de suite mettre à jour les parties avec lesquelles vous n'êtes pas d'accord ou les choses qui doivent être plus approfondies !

Une fois que c'est fait, demandez aux modèles d'IA de vous poser des questions sur le PRD et donnez tout ça, le PRD et vos réponses, à une autre IA pour la mise à jour.

Rincez, Répétez, jusqu'à ce que vous soyez satisfait du document.

Vous pouvez même faire traiter le PRD par plusieurs modèles pour ensuite comparer et fusionner les résultats, en utilisant l'IA, bien sûr :D

C'est là qu'on commence à diverger de la boucle Ralph de base. Au lieu de juste passer ça à l'IA et espérer que les tâches seront bien implémentées, on fait pré-découper et formaliser les tâches et sous-tâches en une liste par une IA !

L'écart grandit encore plus car on sépare l'implémentation des tâches en plusieurs étapes avec :
* une phase de planification qui analyse les requis pour les tâches, le code existant, et fait les recherches nécessaires
* une phase d'exécution pour faire le travail réel
* une phase optionnelle de vérification automatisée (check types, build, tests, ...) avec feedback automatique vers la phase d'exécution en cas d'erreurs
* une phase de review des résultats, qui peut renvoyer vers la phase d'exécution pour plus de raffinement.

Une fois tout ça fait ? la boucle Eric continue pour la phase suivante du plan, tout comme Ralph !

## Mais, Pourquoi... ?

La séparation des préoccupations !

Oui les modèles sont devenus plus intelligents, mais si vous avez joué avec des sub-agents et des skills, vous savez que le prompting n'est pas mort (pour le moment...)

Avoir une séparation propre comme ça aide à avoir de meilleurs prompts pour chaque phase de l'exécution des tâches.

Comme effet secondaire, ça signifie que vous pouvez contrôler quel modèle est utilisé pour quelle phase, peut-être que vous n'avez pas besoin d'Opus tout le long si "il" a fait un super plan !

## A quoi ça ressemblerait ?

On va créer un petit projet à partir d'une idée que j'ai, vous pouvez le faire aussi si vous voulez !

Il s'appelle Tiny-till, une petite app pour avoir une caisse simple pour marchands ambulants.

Mais on va avoir besoin d'un outil pour nous aider ...

### Task-o-matic

Ouais, j'ai déjà fait l'outil en question :D ! [task-o-matic](https://task-o-matic.dev)

J'écrirai plus à ce sujet dans un futur post ! mais vous avez déjà pas mal de contenu à parcourir sur le site lui-même.

J'ai fait gaffe à générer plein de docs et quelques tutoriels pour que vous puissiez déjà essayer si vous voulez !

Mais en gros, ça aide à créer des PRDs, les raffiner, découper en tâches et sous-tâches et finalement connecter tout ça à votre outil de code assité d'IA préféré !

### Allons-y

Pour que l'IA opère proprement, on a besoin d'une stack spécifique, comme ça, on limite les hallucinations !

#### Initialisation et bootstrap

Task-o-matic utilise (https://better-t-stack.dev) en interne pour bootstrap la stack donc faisons ça !

```bash
npx task-o-matic@latest init init --project-name tiny-till \
  --frontend tanstack-router \
  --backend none \
  --package-manager bun && cd tiny-till
```

Boum, un monorepo pour Tiny-till ! Batteries incluses : tailwind, shadcn, script de build et tout :D

Pourquoi `init init` ? vous avez peut-être raté toute l'histoire de l'IA qui code des projets entiers, parfois... c'est pas esthétique, et vous devriez apprendre à pas trop y faire attention (c'est mon avis la-dessus... ou de la flemme...)

Vous aurez besoin d'un fichier .env pour configurer la stack IA.

```ini
AI_PROVIDER=openrouter

AI_MODEL=nvidia/nemotron-3-nano-30b-a3b:free

OPENROUTER_API_KEY=sk_123456azertPOIUY7890i58008
```

#### Documenter les requis de votre projet

Maintenant, on dit à l'IA ce qu'on veut faire, mais pourquoi se limiter à 1 ?

```bash
npx task-o-matic@latest prd create \
  --ai-reasoning 4096 \
  --stream \
  --ai "xiaomi/mimo-v2-flash:free;reasoning=4096" \
  --ai "mistralai/devstral-2512:free:free" \
  --ai "nvidia/nemotron-3-nano-30b-a3b:free;reasoning=4096" \
  --ai "minimax/minimax-m2.1;reasoning=4096" \
  --ai "z-ai/glm-4.7;reasoning=4096" \
  --ai "google/gemini-3-flash-preview;reasoning=4096" \
  --combine-ai "z-ai/glm-4.7;reasoning=4096" \
  "i would like to build tiny-till,
  it will be a small web app, local first (for sparse internet connection) that serve as a very simple till for on the go seller, farmers markets stall, etc...
  the idea came from me watching my baker who does delivery tour twice a week. she is always fighting here calculator to make the tally and she gromle about it a lot
  the idea wwould be only a few screens :
  - product management (add/remove product, name+price (img optional) ) : a list with action buttons, + or edit happen inline (+ at the top)
  - a tally page : grid of product for fast and easy access (row of 2 or 3 for mobile, 4 to 6 on tablet, normal/compact variant, control by setting)
    - clicking on a product adds it to the count
    - number of this product added appear in the card, click on it trigger an input field to enter value with a remove button
  - a setting page : theme, display, import/export catalog
  No saving, it is purely done too calculate the price and is not meant for accounting purposes
  i am using tanstack-router and the project is already set up with tailwind css typescript and shadcnUI"
```

J'utilise des endpoints gratuits pour du "vrai" travail ? Oui, oui, je fais ! Est-ce que ça fausse ma vision de combien le travail IA devrait coûter ? ... pourquoi ça ferait ça ? Non, non, vous êtes juste en train de gâcher la fête là !

#### L'essence n'est pas la seule chose qui doit être raffinée !

Quelques minutes plus tard... je me suis récupéré ça (`cat .task-o-matic/prd/prd-master.md`)[/assets/blackhole/from-ralph-to-eric/prd-master.md] ça a pas vraiment besoin de plus de questions, mais voyons ce que Claude a a dire, d'accord ?

```bash
npx task-o-matic@latest prd question  --stream \
  --file .task-o-matic/prd/prd-master.md \
  --ai-model anthropic/claude-4.5-sonnet --ai-reasoning 1500
```

Bon, répondons à ça... certaines sont pertinentes ! je suppose que c'est pour ça qu'on sort les gros canons !

Répondons !

```bash
npx task-o-matic@latest prd refine  --stream\
  --file .task-o-matic/prd/prd-master.md \
  --ai-model anthropic/claude-4.5-sonnet --ai-reasoning 1500 \
  --output .task-o-matic/prd/prd-master-refined.md \
  --questions prd-questions.json
```

Les questions sont posées interactivement ;)

```markdown
"The PRD mentions using Zustand with persist middleware for the Catalog, but also specifies IndexedDB as the storage layer. Should Zustand's persist middleware be configured to use IndexedDB directly, or will there be a custom sync layer between Zustand and IndexedDB? This affects how image blobs are handled since Zustand persist middleware typically works best with serializable data."

oui, configurer le middleware persist de Zustand pour utiliser IndexedDB directement.
```

```markdown
"For the 'Tap Badge to manually enter quantity' feature, what should happen if a user enters invalid input (negative numbers, decimals, non-numeric characters, or zero)? Should zero be treated as 'remove from cart' or should it maintain the item with 0 quantity until explicitly removed?",

zéro doit être traité comme 'retirer du panier'.
```

```markdown
"The PRD states the tally is 'transient' and held in memory, yet also mentions using sessionStorage. Given that sessionStorage persists across page refreshes within the same tab, this conflicts with the 'privacy and simplicity' goal of resetting on refresh. Should the tally truly reset on refresh (pure memory), or should it survive accidental refreshes during a transaction (sessionStorage)?",

pas de persistance, c'est pas pour la comptabilité et ça doit être uniquement en mémoire, quand un nouveau tally commence, le précédent n'existe plus.
```

```markdown
"With TanStack Router's file-based routing, how should the navigation structure be organized? Specifically, should the Tally Page be the root route ('/'), and if users are on the Settings or Catalog management page when they refresh, should they be automatically redirected back to the Tally Page to prevent data loss confusion?",

oui, / est la page tally, oui rediriger vers la page tally.
```

```markdown
"The image upload feature is marked as 'optional' for products, but the PRD recommends 'no images for MVP' in the risk mitigation. Should image upload functionality be completely excluded from MVP (Phase 1-5), or should the data model and UI be built to accommodate images even if the upload feature is disabled/hidden initially?",

non, je veux les images, imposez juste une limitation de taille stricte, 128*128 px, c'est pas fait pour être une galerie d'images complète, juste une miniature pour l'affichage, amélioration future peut-être pour essayer de redimensionner/optimiser des images plus grosses directement sur l'appareil...mais pas en MVP !
```

```markdown
"For the Import/Export catalog feature, what should happen when importing a JSON file that contains product IDs that conflict with existing products? Should it merge (overwrite matching IDs), append (create duplicates), or prompt the user to choose? Also, should the import validate the JSON schema and handle corrupt/invalid files gracefully?",

écraser et oui, doit valider.
```

```markdown
"The 'Compact vs Normal' view toggle affects card size, but how should this interact with the responsive column count? For example, if a tablet user sets 6 columns in Normal view, should switching to Compact view automatically increase columns (e.g., to 8) to utilize the space savings, or should column count remain fixed per the user's explicit setting?",

oui, augmentation auto, c'est pour ça qu'on veut compact !
```

```markdown
"Given the Turborepo setup mentioned in the stack, is this application intended to be part of a monorepo with potential future packages (e.g., a companion admin dashboard, analytics service)? If so, should the data models and storage utilities be architected in a shared package from the start, or is this truly a standalone application for now?",

non, package unique pour l'instant, on verra après pour le reste. gardons ça simple pour l'instant.
```

Bon, cette petite astuce vient de me coûter un joli 15 cts, plus ou moins 10x plus que la première génération de PRD...

Je sais pas ce qui est le plus incroyable... que

* 1 appel coûte plus que les 10 précédents,
* je puisse me plaindre qu'un document de 2 jours de travail coûte 15 cents pour seulement quelques secondes de travail !
* un document qui vaut 2 de mes jours de travail coûte 15 cents à produire...en seulement quelques secondes...

J'ai pas encore décidé...bon bref, passons à la suite et restons pas bloqués !

#### Les petites retouches et c'est parti

Quand j'ai dit secondes, j'ai menti, j'ai passé 5 minutes à éditer le fichier. pour fixer les versions de lib, marquer le travail d'install et de config comme fait, et, enfin, définir les attentes pour le design.

la dernière chose qu'on a a faire, c'est demander à une IA de découper en tâches principales.

encore une fois, je vais pas en faire qu'une seule, mais cette fois, je vais demander à Claude d'être le créateur de tâches final, à partir des entrées des autres !

```bash
npx task-o-matic@latest prd parse  --ai-reasoning 4096 --stream \
  --ai "xiaomi/mimo-v2-flash:free;reasoning=4096"\
  --ai "nvidia/nemotron-3-nano-30b-a3b:free;reasoning=4096" \
  --ai "z-ai/glm-4.7;reasoning=4096" \
  --combine-ai "anthropic/claude-4.5-sonnet;reasoning=4096"
```

Et voila encore 8.2 cents brûlés en offrandes aux dieux du token, mais en retour, on a un découpage détaillé des tâches requises pour finir le projet !

On a encore à découper ces tâches par contre... Pour les rendre plus digérables, même pour les meilleurs modèles IA à l'heure actuelle !

Ca serait une bonne idée de revoir les tâches en détail avant de les découper, pas faire du vibe-planning comme un neuneu ! (devinez ce que j'ai fait ^^)

```bash
npx task-o-matic@latest tasks split  --all --stream \
  --reasoning 4096 \
  --ai "xiaomi/mimo-v2-flash:free;reasoning=4096"\
  --ai "nvidia/nemotron-3-nano-30b-a3b:free;reasoning=4096" \
  --ai "z-ai/glm-4.7;reasoning=4096" \
  --combine-ai "anthropic/claude-4.5-sonnet;reasoning=4096"
```

Je pense pas que Claude soit nécessaire là, mais j'avais mes $3 de crédit openrouter à brûler avant la fin du mois donc bon... on sort l'artillerie lourde !

Et bim, 30 centimes de plus ! mais maintenant... on est vraiment prêts ! Presque...

#### AGENTS.md

Ou CLAUDE, ou GEMINI, dépend de votre outil de code assité préféré, Pour moi, c'est opencode je vais lancer le prompt /init dans opencode !

```bash
opencode run "/init"
```

c'est pas vraiment obligatoire, mais c'est quand meme une bonne histoire d'eviter les plus grosse conneries et de recentrer quelques comportements pour certaines choses, du coup, on rajoute ca :

* Pas lancer le server de dev
* pas démarrer de processus en arrière-plan/de longue durée
* pas utiliser `:any`, `as any` ou `any` comme type, je veux une base de code typesafe
* avant de dire "Jai finiiiii", `bun run check-types` et `bun run build` doivent tous les deux réussir
* corriger les erreurs LSP quand elles arrivent
* utiliser les composants shadcn autant que possible
* rester DRY et préférer créer des composants personnalisés et des utilitaires que répéter du code
* utiliser les compétences adaptées quand c'est possible (la compétence frontend-design est obligatoire quand on travaille sur le frontend)
* que c'est un projet d'app statique qui sera hébergé sur github pages
* utiliser Context7 MCP au cas où plus de documentation ou une documentation à jour est nécessaire (car la connaissance est certainement en retard à cause de la date limite de training)

```bash
opencode run "Add the following to the AGENTS.md, remove any conflicting instructions you created, these take precedence :
* Not to run the dev server
* not start background/long running processes
* not to use `:any`, `as any` or `any` as type, I want a typesafe codebase
* before claiming success, `bun run check-types` and `bun run build` must both succeed
* to fix LSP error when they happen
* use shadcn component has much as possible
* stay DRY and prefer creating custom components and utilities than repeat code
* use adapted skills when possible (frontend-design skill is mandatory when working on the frontend)
* that it is a static app project that will be hosted on github pages
* to use Context7 MCP in case more documentation or up to date documentation is needed (as the knowledge is certainly behind because of cutoff training date)" -c
```

J'ajouterai peut-être plus pendant que l'agent travaille si je vois des erreurs récurrentes et des gourdineries qui arrivent trop souvent (... si je regarde passer le train... c'est pas dit XD)

#### Et maintenant, on fait rouler Eric...

Bon les gars, cachez vos parents car on va laisser Eric y aller !

Parce que je suis El CheapoDev DelBrokeCasa, je vais utiliser mon GLM coding plan pour coder, comme ça, je vais pas eclater ma tirelire et c'est assez intelligent pour un truc comme ça je pense !

Si vous préférez claude code, utilisez l'option `--tool claude`. (ou codex/gemini/kilo) mais opencode est plus sympa car il stream le contenu (en partie en tout cas) donc vous voyez ce qui se passe (meuuuuh !) !

```bash
npx task-o-matic@latest tasks execute-loop --include-prd \
  --plan --plan-model zai-coding-plan/glm-4.7 \
  --review --review-model zai-coding-plan/glm-4.7 \
  --model zai-coding-plan/glm-4.7 \
  --validate "npm run check-types && npm run build"
```

Et maintenant, vous attendez, un café, un gouter, un peu plus de café, le dîner et pis le p'tit déj probablement, ça va prendre un moment ^^

### Résultat

Une demi-journée plus tard, Eric a terminé la tâche avec succès. youhou \o/

`npm run dev`, navigateur vers http://localhost:3001 et eeeet, ça marche pas.... XD

J'ai une super page d'erreur qui me parle d'une sorte de "exceeded depth error blablabla"... Zustand... je déteste PUTAIN Zustand !

J'aurais pu aller ouvrir le projet, lire quelques-unes des 35970 lignes de... **35970 LIGNES DE CODE** ??? Naaah, gros, c'est mort de chez mort !

Bien sûr, j'ai demandé à GLM de corriger l'utilisation degueulasse de Zustand, et j'ai même dû passer quelques minutes à hurler sur un problème de redirection vers /... J'avais l'impression d'être un homme des cavernes quand même !

Je veux dire, devoir ouvrir un outil ? Pour faire... **du travail** ?? Nan mais Allo quoi, c'est 2022 ou quoi ?

J'ai rien testé encore, donc je suis à peu près sûr qu'il y aura quelques autres problèmes, mais le serveur de dev tourne, je peux naviguer dans l'app sans erreur (même en console) donc c'est pas mal du tout !

Je ferai peut-être un autre article plus tard, pour vous tenir au courant de ce que j'ai eu à faire pour rapprocher un peu plus de l'idée originale (si nécessaire ^^)

## Vous en pensez quoi ? On va où après ?

Donc c'est la fin (de cet article) ! Vous en pensez quoi ? vous avez essayé une technique similaire ? C'est quoi le plan après, parce que bon...

Si vous êtes intéressés, le repo peut être trouvé sur [github](https://github.com/DimitriGilbert/tiny-till). Le code est génial ?

Et pour [task-o-matic](https://task-o-matic.dev), le [repo est sur github](https://github.com/DimitriGilbert/task-o-matic) donc n'hésitez pas à faire un tour ;)

Et pour la "Boucle Eric", comment faire vous-même ? Yaka demander à l'IA :D vous pouvez lui demander d'écrire du code ! Donc un petit

```markdown
tu pourrais créer un script bash qui exécuterait la "Boucle Eric" avec des options personnalisées ?

en me laissant spécifier le projet, quel modèle utiliser et quand, je veux tout pouvoir configurer via des options !

utilise la commande --help de task-o-matic si t'as besoin de doc !
```

[voici le résultat](/assets/blackhole/from_ralph_to_eric/eric_loop.sh), votre Eric Loop a vous, elle est pas belle la vie ?!

Hope you enjoyed, I'll see you around
9:T2f74,
## Why ?

I looked for something like that and did not find any, so I am building one !

I will take this opportunity to build it in public, as much as possible ! Meaning most prompts and conversations will be available for you to read and "inspire" yourself !

Why not all conversations ? Well, sometimes, I forget, other times... I'm swearing way too much so it does not bring any value ! (I am grumpy and irritable as a default state, pain makes it worst... at the moment, the pain level oscillate between 2 and 5 out of 10 ^^)

I also want to show others that you can actually create something with AI doing most of the grunt work of dev with "careful" orchestration.

Is it going to be perfect ? XD what a stupid question ! NO ! 'f course not !

Can it get the job done ? I certainly hope so !

## What is it already ?

It is a library/marketplace of Shadcn ui components ! I was tired of hunting for cool components and blocks all around the internet !

Between github lackluster SEO and worst devs' website's one, it is really hard to come across new components, and it is a shame cause some are fantastic !

Also, as a creator of some component (with awful terrible SEOed sites...) i kind of feel unseen, sooo [cn-registry.dev](https://cn-registry.dev) was born !

## The process

Like I said, this is a build in public thing, so I am going to try and share what I learned with you (and my future self if this MF wants to listen !).

How I did things, what worked, what did not really do so, my fuck ups, hope and delusions...

In a sense, I am going to make mistake and look like a fool so you don't have to !

Let's start at the beginning...

### The Idea

Plenty of time I see people asking for ideas on things to build, to other humans, or worse, AI...

No... please don't ! not here !

I sincerely thing ideating is **The** thing that will separate us from machines for awhile still ! You should not delegate that !

"But how do I find ideas then ?" might you witty reader ask me ! And so rightful would you be !

So let me answer you with a question, that could trigger some ideation !

Are there no problem that need solving, in the place that you live in ?

Poetic rhymes aside, solve one of your damn fking problem man (or girl, you are welcome to do so too !) !

That way, even if you don't end up having clients, you'll have solved one of your problem !

For me the problem was "lazy ass dev want find shadcn components easy" ! There you go, how do you solve that problem ?!

### Initial plan

Nothing ground breaking or revolutionary, a dumb directory would do the trick... but that would lack a bit of flair... wouldn't it ?

Solving a simple problem does not necessarily mean a simplistic solution and I was already very keen on over-engineering my own tombstone sooo, let's go for that !

Why not sprinkle some social stuff on it ? It's not because I am limited regarding those skills that others are !

User account, likes, comments ! there you go ! Now we can socialise !

We have the basic Idea of what we want ? Yeah ?

Yeah ! Now we can go bother some AI with it !

### Start proompting

```
I want to build a website using nextjs 15 and shadcn  (i got the stack figured out !) and I need a complete plan to create the front end !
the project is called "cn-registry" and it will be a registry of shadcn components and tools, because hunting for them feels like a full time job.
I want you to plan the needed components and pages, I aim for maximum reusability so if something make sense standalone, it should be ! i do not want you to create code, just the plan !
I want a home page with carousels, one with the 10 latest components, one with the trending one
components will have a name, a description, a repo link, a website, an installation url, categories and each should have a dedicated page with the copiable install command, the repo readme and github info, some showcase with code toggles
Tools will be the same but the install url might be for an npm package or not exists
I want a search page with card or list results and filters on categories
same for tools but on a different page
I want to have a star rating system and user account where user can see the components they stared
User will be able to comment on components
```

As you can see, simple, (in)efficient, (de)organized ! And a couple refinement later, I have my intermediary prompt for V0 !

I wont bore you with the mile long prompt (you have convo link in repo ^^) but it was a good mile long and i did not change much !

Suffice to say that after that I had some "mock data stuffed" frontend prototype for... where am I going to put that... ?!!

### Select your stack

I already did, and you probably should think of that before proompting to be honest ! For me it was easy, I just reached for my current default stack Nextjs front and back, trpc, tailwind and shadcn.

Yes, it is boring. Yes, everyone is doing the same. I don't care.

I start a gazillion projects (and a half) every month cause I am unable to focus on one thing at a time, it doesn't mean I have the cognitive bandwidth to try and learn new stuff every times !

There is also plenty of good docs and resources for all these, which make it easy to work with without too much prior experience

Plus, as a massive, Massive (MASSIVE !) bonus : It works well with AI ! (mostly, sometimes)

Am I saying you should pick this stack ? If you like it, yes, otherwise, i couldn't care less !

Pick what you know, the new hyped stuff or what tickles your fancy ! Really, I couldn't care less, but I care for you to do it right ! Use [better-t-stack](https://better-t-stack.dev) !

yes, this is authoritative, but if your stack is in, use it ! 1 command, boom, project scaffolded and ready to go in seconds (thank me later)

### Let the music start !

```markdown
[x] Idea
[x] Concept
[x] project initialized
[x] frontend prototype
[ ] proper plan
```

Ooooh ? You thought... ? you thought I was going to open my favourite AI agent and start vibing away ?

no no no ! This is not the way ! You are going to go back to your first AI pal you used for the front end prototype plan and you are going to ask it for another plan !

```markdown
I am using the latest version of drizzle orm and postgres so i would like you to carefully plan the whole complete data model I will need,
including user setting and admin/creator utilities table tha migth be needed in the project. we will iterate to align with my goal but try to makee it very comphrehensive
```

It did a pretty good job with my previous frontend plan alignement in one shot soooo...

```
cd workspace/Code/cn-registry;
claude
"I want you to implement the server complete side of the project following this :
  **cn-registry Complete Data Model Plan**
...
  better auth is already setup and running,
  I want schema definition and trpc routes with complete access management for security.
  make sure the apps build when you are done with the backend.
"
```

Et en voiture Simone !

Realignment aside, this got me a building backend that I asked the agent to wire up to the frontend.

### Broken string and other misadventures...

Were you waiting for it ? To be completely honest, I did not think it was going to be so early...but yes, no plan survive contacts with the enemy.

Which enemy ? Trpc ! No no ! not trpc trpc, trpc version and the fact that a major revision came out between the training cut off date and the release/adoption of trpc version...

What does this mean ? AI follows patterns it "knows", guess what it does when it doesn't know the patterns ?

Yup, it's "hallucination time" baby ! Wooooooot Wooooooot ! -\_- Can you feel the pain ? ok, good.

But for a villain in the story, a Hero will come forward, you see

A hero to help the dragons slay, and its name is LLM dot txt

```markdown
my stack is using the following package.json files
Agents often fails on trpc usage because their knowledge is out of date.
I would like you to fetch the lates trpc docs and prepare a comprhensive but concise llm.txt for my agents to work with.
it is only destined towards LLM so you can forgo absolutely all the fluff and present information in the best possible way for you to ingest it efficiently
```

I fed the responded file to my agent, and behold, a few prompts later, I was served dragons' heart for dinner !

### more, More, MOOOOAR

Do you feel the power rising ? The exhileration of AI acceleration ? Is your brain broken and addicted yet ?

Nooo ? well, we are going to have to work on that ! Maybe it's because we lack documentation ?

You are very right ! So I asked gemini cli to do that !

Unfortunatly, i do not have this prompt anymore, but it went something like :

```
I am working on this project [description]
the front and backend are prototyped, the apps build but i did not test anything yet.
I would like you to analyze it very (very ! VERY !!) carefully !
you have to open many files to make sure you understand the app and how it is built.
once done, please create some documentation about that.
```

to which I invariably had to complement after the first response (exact paraphrasing)

```
oooOOOOH FFS ! HOW THE F DO YOU WANT TO UNDERSTAND ANYTHING, YOU OPENED 5 FILES, 2 OF THEM WERE PACKAGE.JSON ! OPEN ALL THE FILES ! **ALL OF THEM**
```

Seriously, how does anyone work with gemini these days ? It ended up giving me some decent documentation after that flogging though !

What ? Why do I make the model document the thing already ?

```
Good. now that you have a complete understanding of the full project, i want you to create a plan to finish the implementation of the existing base.
then, I want you to create a plan in better.md that outlines possible enhancement to the base application.
One I want is a cart system so a user can add component to it and get a complete install command for all the components he selected.
be creative and come up with functionalities that would make this platform stand out
```

There you go, this is why ! now that you have something more than a couple of sentence, agents can stretch their legs !

What do similar enough architectures and software have as functionalities ? It will know ! You'll be left with the cherry picking and it might even give you more ideas !

### Tidy up and go forward

Armed with gemini's assertion of the codebase, I asked claude to do the work (you would have to pay me to allow gemini modifying my files !)

Once complete I asked it to create a proper plan for the extra functionalities I chose

- cart system
- project system
- github integration
- creator profiles

It gracefully did that while I started testing the app. Systematic clicking and typing, going from error to error, indexing them by small groups, asking my agent to take care of them.

This is the perfect occasion to start having a look at the code... yes, just now.

To be fair, I was probably less than 3 hours in and I also come from a time where bootstrapping an app was probably that long sooooo... not saying this is good, but I have done that a dozen times already and I know what to expect.

Bug hunting took an hour or so, nothing major, missing "use client", dumb state management, over complicated logic, a bunch of alerts and prompts, in short, claude's specials (I was spared me the blueish purple gradient this time though...)

Implementing the improvement plan was business as usual and took around another 3-4 hours

```
in @improvements.md implement phase/part ...
```

### One day at a time

I realize this is getting long, and, well it is the end of day 1 so I am going to stop here for now !

At that moment I had a mostly working app, with an admin side i could get in, component and tools could be added.

And as my eyes were all closing, I could not see shadows brewing

Covering me with joy and warm for my app worked like a charm

An innocent small idea that would become ...[find me a noun of something bad finishing by the sound a, i need a rhyme]

In the mean time, here is the [demo](https://cn-registry.dev) and the [repo](https://github.com/DimitriGilbert/cn-registry), feedback greatly appreciated as always !
a:T3674,
## Pourquoi ?

J'ai cherché un truc comme ça et j'ai rien trouvé, alors je le construis !

Je vais en profiter pour le construire en public, autant que faire se peut ! Ca veuut dire que la plupart des prompts et des conversations seront disponibles pour les lire et s'en inspirer !

Pourquoi pas toutes les conversations ? Euuuh alors... bon... parfois, j'oublie. Eeeet euuuh d'autres fois... disons que c'est pas tellement family friendly ^^ ! (Je suis grincheux et irritable par défaut, quand j'ai mal, c'est pire... en ce moment, ca oscille entre 2 et 5 sur 10 ^^)

Je veux aussi montrer/prouver a d'autres qu'il est possible d'utiliser l'IA pour generer la majorité du code avec une "orchestration" minutieuse.

Est-ce que ce sera parfait ? XD quelle question stupide ! NON ! Bien sûr que non !

Est-ce que ça va faire le travail ? J'espère bien !

## Qu'est-ce que c'est déjà ?

C'est une bibliothèque/un marketplace de composants Shadcn ! J'en avais marre de chercher des composants et des blocs sympas un peu partout sur Internet !

Entre la SEO médiocre de GitHub et celle encore pires des sites de développeurs, c'est vraiment pas facile de tomber sur de nouveaux composants, et c'est dommage car certains sont fantastiques !

En plus, en tant que créateur de composants (avec des sites... dont le SEO est affreux...), je me sens un peu invisible, alors [cn-registry.dev](https://cn-registry.dev) est né !

## Le processus

Comme je l'ai dit, il s'agit d'une build in public, alors je vais partager avec vous ce que j'apprends (et mon futur moi si ce con se met a ecouter !).

Comment j'ai fait, ce qui a fonctionné, ou pas, mes conneries, mes espoirs et mes illusions...

En gros, je vais faire des erreurs et avoir l'air d'un idiot pour que vous n'ayez pas à le faire !

Commençons par le début...

### L'idée

C'est souventque je vois des gens demander des idées sur quoi construire, à d'autres, ou pire, à l'IA...

Non... s'il vous plaît, pas ici !

En vrai, l'idéation (oh je vais pas traduire un mot qu'existe pas non plus !) est **la** chose qui nous resteras face machines pour encore un moment ! Faut pas déléguer ca !

"Mais comment trouver des idées alors ?" pourrait me demander mon lecteur astucieux ! Et vous auriez tout à fait raison de le faire !

Alors laissez-moi vous répondre par une question qui pourrait déclencher un peu d'idéation !

Y a-t-il des problèmes à résoudre, là où vous vivez ?

_les 3 phrases d'avant marche tellement pas en francais, mais je les laisse tellement la traduction est moisie x-)_

Traduction en carton à part, résous un de **tes** problèmes mec (ou meuf, z'êtes également les bienvenus !) !

Comme ca, même si personne s'en sert, t'auras résolu un de tes problèmes !

Pour moi, le problème était "dev faignasse chereche composant shadcn facilement" ! Et voila, maintaint, comment on s'occupe de ca ?!

### Plan initial

Rien de révolutionnaire ou de génial, un bete annuaire ferait l'affaire... mais ca manque un peu de pepse... non ?

Problème simple ne signifie pas nécessairement solution simpliste et j'aime deja bien les usines a gaz alors, allons-y !

Pourquoi ne pas ajouter un peu de social ? C'est pas parce que je suis incompétent (ca marche aussi en 2 mots) sociales que les autres le sont !

Comptes utilisateurs, likes, commentaires ! Et hop, maintenant on socialise !

Bon, on a l'idée de base en entier ? Oui ?

Oui ! Et bhe y'a plus qu'a aller embêter une IA avec ça !

### A vos marques, pret, proomptez !

Oui, les prompts sont encores en anglais, ca marche mieux. vraiment !

```
I want to build a website using nextjs 15 and shadcn  (i got the stack figured out !) and I need a complete plan to create the front end !
the project is called "cn-registry" and it will be a registry of shadcn components and tools, because hunting for them feels like a full time job.
I want you to plan the needed components and pages, I aim for maximum reusability so if something make sense standalone, it should be ! i do not want you to create code, just the plan !
I want a home page with carousels, one with the 10 latest components, one with the trending one
components will have a name, a description, a repo link, a website, an installation url, categories and each should have a dedicated page with the copiable install command, the repo readme and github info, some showcase with code toggles
Tools will be the same but the install url might be for an npm package or not exists
I want a search page with card or list results and filters on categories
same for tools but on a different page
I want to have a star rating system and user account where user can see the components they stared
User will be able to comment on components
```

Commeon peut le voir, simple, (in)efficace, (dés)organisé ! Et quelques raffinements plus tard, j'ai mon prompt intermédiaire pour V0 !

Je ne vais pas vous ennuyer avec le prompt interminable (vous avez le lien de conversation dans le repo ^^), mais il était interminable et j'ai pas beaucoup changé de choses !

Apres le passage chez V0, j'avais un prototype de front-end avec des données simulées pour... Mais je vais le mettre où ça moi... ?!

### Sélectionnez votre stack

Perso, je l'ai déjà fait, et vous devriez probablement y penser avant de prompt en vrai ! Pour moi, c'était facile, j'ai pris ma stack par défaut du moment : Nextjs front et back, trpc, tailwind et shadcn.

Oui, c'est ennuyeux. Oui, tout le monde fait la même chose. Je m'en tape le coquillard !

Je commence un milliard de projets (et demi) chaque mois parce que je suis incapable de me concentrer sur une seule chose à la fois, ca veut pas dire que j'ai la de bande pasaante pour apprendre de nouvelles choses à chaque fois !

Il y a aussi pas mal de bonnes docs et ressources pour toutes ces technos, ca facilite le travail meme sans trop d'expérience préalable.

Et pour rien gacher, un gros, Gros (mais genre GROS) bonus : Cela fonctionne bien avec l'IA ! (enfin, des fois, un peu)

Est-ce que je dis que vous devriez choisir cette stack ? Si vous l'aimez, oui, sinon, je m'en fiche complètement !

Choisissez ce que vous connaissez, la nouvelle stack à la mode ou ce qui vous titille ! Vraiment, je m'en fiche complètement, mais je me soucie que vous le fassiez correctement ! Utilisez [better-t-stack](https://better-t-stack.dev) !

Oui, c'est autoritaire, mais si votre stack est dedans, utilisez ca ! 1 commande, boom, projet tout chaud et prêt à decoller en quelques secondes (remercie moi plus tard)

### Laissez la musique commencer !

```markdown
[x] Idée
[x] Concept
[x] projet initialisé
[x] prototype frontend
[ ] plan approprié
```

Ooooh ? Vous pensiez... ? vous pensiez que j'allais ouvrir mon agent IA préféré et commencer à vibe coder ?

uuuhh non non non ! pas la, pas encore ! la, on retourne à notre premier pote qu'on a utilisé pour le plan du front-end et on va lui demander un autre plan !

```markdown
I am using the latest version of drizzle orm and postgres so i would like you to carefully plan the whole complete data model I will need,
including user setting and admin/creator utilities table tha migth be needed in the project. we will iterate to align with my goal but try to makee it very comphrehensive
```

Comme j'ai deja reorientez les choses pour le front end, j'ai eu le droit a un joli plan en one shot, donc...

```
cd workspace/Code/cn-registry;
claude
"I want you to implement the server complete side of the project following this :
  **cn-registry Complete Data Model Plan**
...
  better auth is already setup and running,
  I want schema definition and trpc routes with complete access management for security.
  make sure the apps build when you are done with the backend.
"
```

Et en voiture Simone !

Mis à part les petites reorientations, ca m'a donné un backend "fonctionnel" (a une vache pres !) donc j'ai demandé à l'agent de connecter ca au frontend.

### C'est Bestel, il a mis la cassette et puis pouf !

Vous l'attendiez ? Pour être tout à fait honnête, je ne pensais pas que ce serait si tôt... mais oui, aucun plan ne survit au contact de l'ennemi.

Quel ennemi ? Trpc ! Non non ! pas trpc trpc (c'est très bien trpc !), la version de trpc et le fait qu'une révision majeure est sortie entre la date de coupure d'entrainement de claude et maintenant......

Qu'est ce que donc que ca pourrait il vouloir bien dire toussa ? Les LLMs suivent des schémas qu'elles "connaissent", et devinez ce qu'elles font quand elles connaîssentt pas les schémas ?

Ouep, c'est ca, elles "hallucinent" leurs mamies ! Wooooooot Wooooooot ! -\_- J'espere que vous sentez la douleur !

Mais pour un méchant dans l'histoire, un Héros se présentera un beau soir

Un héros pour aider les dragons à être tués, et son nom est LLM point txt

_eeeett vous savez a quoi on reconnaît des bonnes ryhmes ? elles se traduisent toutes seules!_

```markdown
my stack is using the following package.json files
Agents often fails on trpc usage because their knowledge is out of date.
I would like you to fetch the lates trpc docs and prepare a comprhensive but concise llm.txt for my agents to work with.
it is only destined towards LLM so you can forgo absolutely all the fluff and present information in the best possible way for you to ingest it efficiently
```

J'ai gavé la réponse à mon agent, et après quelques prompts, on m'a servi le cœur du dragon pour le dîner !

### encore, Encore, ENCOOORE

Vous sentez la puissance monter ? L'exaltation de l'accélération par l'IA ? Votre cerveau est-il déjà accro ? Non ? Eh bhe on va devoir travailler là-dessus !

Manque de la doc peut etre ?

Mais tout a fait tout a fait, allons voir ce bon vieux gemini !

je n'ai plus ce prompt, mais c'était quelque chose comme :

```
I am working on this project [description]
the front and backend are prototyped, the apps build but i did not test anything yet.
I would like you to analyze it very (very ! VERY !!) carefully !
you have to open many files to make sure you understand the app and how it is built.
once done, please create some documentation about that.
```

que j'ai invariablement dû compléter après la première réponse par un joyeux (paraphrase exacte)

```
oooOOOOH FFS ! HOW THE F DO YOU WANT TO UNDERSTAND ANYTHING, YOU OPENED 5 FILES, 2 OF THEM WERE PACKAGE.JSON ! OPEN ALL THE FILES ! **ALL OF THEM**
```

Sérieusement, qui arrive a bosser avec gemini (vrais question !) ? Bon apres cette petite sceance de fouettage gemini m'as finalement pondus une doc correct !

De quoi, quoi ? Pourquoi j'ai fait documenter le taf par l'IA ?

```
Good. now that you have a complete understanding of the full project, i want you to create a plan to finish the implementation of the existing base.
then, I want you to create a plan in better.md that outlines possible enhancement to the base application.
One I want is a cart system so a user can add component to it and get a complete install command for all the components he selected.
be creative and come up with functionalities that would make this platform stand out
```

Voilà pourquoi ! Pour bien bosser les LLM ont besoin de plus de 2 phrases de contexte, avec une vision plus précise du code, l'IA pourra planifier plus efficacement !

Quelles fonctionnalités et architectures sont utilisé dans des logiciels similaires ? Il le saura ! Z'aurez plus qu'as faire vos emplettes et ca pourras meme debloquer d'autres idées !

### Vous en avez mare de ces details ? et bhe on va vous en débarrasser

Armés de l'étude de gemini sur mon code, j'ai demandé à claude de faire le travail (Faudrais me payer pour laisser gemini s'approcher de ma codebase en ecriture !).

Une fois finis, je luiai demandé de créer un plan plus precis pour les fonctionnalités supplémentaires que j'ai choisies

- système de panier
- système de projet
- intégration GitHub
- profils créateurs

Il l'a tres grâcieusement fait pendant que je commençais à tester l'application.

Click frenetique et topotage systématiques, passage d'erreur en erreur, indexation par petits groupes, envoyé a l'agent qui n'en fait qu'une bouchée !

C'est l'occasion parfaite pour commencer à examiner le code... oui oui, que maintenant.

En vrai, J'y etais depuis moins de 3 heures et j'ai commancé ma carriere a une époque où tout mettre en place pour dev une application prenait probablement aussi longtemps donc...

je ne dis pas que c'est bien, mais ca fait une bonne douzaine de fois que je commence du dev comme ca et je sais à quoi m'attendre en terme de code.

La chasse aux bugs a pris environ une heure, rien de majeur, "use client" manquant, mauvaise gestion d'état, logique trop compliquée, un tas d'alertes et de prompts, en bref, les spécialités de claude (et j'ai pas subi les gradients bleu violacé cette fois-ci ...)

L'implémentation du plan d'amélioration ? Pareil, simple efficace, en 3-4h de plus :

```
dans @improvements.md implémenter la phase/partie ...
```

### Un jour à la fois

Bon... ce post devient long, et comme c'est la fin du jour 1, je vais m'arrêter ici :D !

À ce moment-là, j'avais une app quasi fonctionnelle, avec un côté admin, les composants et les outils pouvaient être ajoutés.

_je vais les laisser comme ca aussi les suivantes, le jours ou l'IA traduit les ryhmes, on est cuit les lapins!_

Et alors que mes yeux se fermaient tous, je ne pouvais pas voir les ombres qui se formaient.

Me couvrant de joie et de chaleur pour mon application qui fonctionnait comme un charme.

Une petite idée innocente qui deviendrait... [trouvez-moi un nom de quelque chose de mauvais se terminant par le son a, j'ai besoin d'une rime].

En attendant, voici la [démo](https://cn-registry.dev) et le [dépôt](https://github.com/DimitriGilbert/cn-registry). Vos retours sont, comme toujours, grandement appréciés !
b:T11ee,
Hello everyone, I’d like to introduce LiteChat, a project I created.

[Repository](https://github.com/DimitriGilbert/LiteChat) and download link [here](https://github.com/DimitriGilbert/LiteChat/releases) (available in French, English, Spanish, Italian, and German).

LiteChat is an AI chat application I built to interact with both local and remote LLMs—all within your browser. It’s designed with a "local-first" philosophy, requiring only an HTTP server to run, with everything else handled in your browser! No tracking, no accounts—you bring your own API keys. Data is saved in an IndexedDB database, and you can synchronize your conversations using Git.

Yes, entirely in the browser! 😛 To make this work, I also implemented a virtual file system (again, all in the browser). You can clone repos and include files from the VFS in your conversations! But manually selecting files was tedious, so I integrated tools for managing the VFS and Git.

With the core architecture in place, I added support for HTTP MCP servers. However, standard stdio servers were still missing, so I also built a bridge (rewritten by AI from `mcp-proxy`) to make them work (you can deploy it anywhere, but it’s not secure!).

Sure, AI is fun, but I was getting tired of text-only interactions. So, I added support for Mermaid diagrams and HTML forms (now you don’t even need to think about how to phrase your requests!). Sure, Mermaid diagrams aren’t the prettiest, but since I added a workflow module with visualizations based on [reactflow.dev](https://reactflow.dev), I also included a way for LLMs to generate them! And since plain text isn’t very engaging, there’s also a "Beat" block that uses [strudel.cc](http://strudel.cc/) to add auditory feedback.

Testing was getting repetitive, so I created a prompt library with templates—now you just fill in a form! (Okay, maybe I also needed it for workflows…)

What’s an Agent, you ask? It’s a system prompt, tools, and task-specific prompts! So, you also get a library for those.

Prompts and agents can integrate into workflows (that’s what they’re designed for!), but you also have transformation steps, user code execution, and custom prompts to facilitate transitions.

As you might have guessed, if I have a way to execute code in workflows, why not run AI-generated code? Yes, you can! In Python or JavaScript. And if you’re feeling adventurous, you can run JavaScript in "unsafe" mode (`eval` and all—that’s code for "yolo" 😆). This can produce cool stuff, like [this one-shot Three.js scroll shooter](https://dimitrigilbert.github.io/racebench/scroller/index.html). You can export it in one click (the template is a bit ugly, but I’ll improve it!).

To avoid losing context, all these UI blocks can be "activated" (or rather, suggested) using rules. Of course, you can add your own rules! There’s even a button to ask the AI to pick the best ones for your current prompt.

You also get the usual regenerate (with a different model if you like) and forking options. You can even edit responses manually to remove unnecessary parts. Code blocks are also editable with syntax highlighting for common languages (but no autocompletion or fancy features—let’s not push grandma into the bushes!).

To top it all off, you can organize AI "races" with an unlimited number of participants (though that depends on your budget, haha). It’s great for benchmarking or seeing which model will replace us first. I even built a small tool that takes exported race conversations and turns them into a benchmark site (currently more focused on the JS execution block: [https://dimitrigilbert.github.io/racebench/scroller/index.html](https://dimitrigilbert.github.io/racebench/scroller/index.html) for the "game" mentioned earlier).

I’m sure I forgot a few things, but you’ve got the gist! 😊

The hosted version is on GitHub Pages, with no tracking and no accounts! You bring your own API keys. You probably won’t be able to use the hosted version for your local LLM due to HTTPS/HTTP restrictions, but as I said, you can [download it](https://github.com/DimitriGilbert/LiteChat/releases) and host it with a simple HTTP server. There are also localized versions for French, Italian, German, and Spanish. A short (and incomplete) tutorial playlist if you’re feeling lost: [https://www.youtube.com/playlist?list=PL5Doe56gCsNRdNyfetOYPQw_JkPHO3XVh](https://www.youtube.com/playlist?list=PL5Doe56gCsNRdNyfetOYPQw_JkPHO3XVh)

I hope you enjoy it, and constructive feedback is greatly appreciated! 😊

---
c:T156f,
Salut a tous, pour mon premier post, je vous presente LiteChat dont je sui le créateur.

[Repo](https://github.com/DimitriGilbert/LiteChat) et ici [pour télécharger](https://github.com/DimitriGilbert/LiteChat/releases) (en francais, anglais, espagnol, italien et allemand).



C’est un chat IA que j’ai créé pour pouvoir utiliser des LLM locaux et distant, le tout dans votre navigateur. Il est conçu pour être “local first” et n’a besoin que d’un serveur HTTP pour fonctionner, tout le reste c’est dans votre navigateur ! Pas de tracking, pas de compte, vous venez avec vos clé d’API ! Les données sont sauvegardées dans une base de données IndexeDB et vous pouvez synchroniser vos conversations en utilisant git.

Oui, dans le navigateur :P Pour ce faire, j’ai aussi dû implémenter un système de fichiers virtuel (oui, toujour dans le navigateur en utilisant ). Vous avez donc accès aux deux, tant qu’a faire ! Vous pouvez cloner un repo et joindre des fichiers du VFS dans vos conversations !

Mais comme la sélection manuelle des fichiers, c’était une corvée, j’ai intégré des outils pour le VFS et git !

Ensuite, comme l’architecture de base était là, et bien j’ai ajouté le support des serveurs MCP HTTP, mais il manquait toujours les serveurs stdio …, donc j’ai aussi “fait” un bridge (réécrit par l’IA à partir de mcp-proxy ) pour les utiliser (vous pouvez le déployer où vous voulez mais ce n’est pas sécurisé !)

Apres, c’est bien mignon l’IA, mais j’en avais un peu marre du texte seul, du coup, j’ai ajouté le support des diagrammes Mermaid et des formulaires HTML (Comme ca on a meme plus besoin de réfléchir a quoi lui dire a la machine !). Bon… après…les diagrammes Mermaid c’est un peu moche, et comme j’ai ajouté un module de workflow avec des visualisations basée sur [https://reactflow.dev/], j’ai aussi ajouté un moyen pour les LLM de vous en créer ! Et puis comme le text ca fait pas beaucoup de bruit, il y a aussi in block “Beat” qui utilise (http://strudel.cc/) pour aussi en profiter de maniere auditive !

Et puis bon, en testant, toujours taper les mêmes prompts avec juste quelques différences c’était lourd aussi, j’ai donc fait un module de bibliothèque de prompts avec des modèles pour qu’y ai plus qu’a remplir un formulaire ;) (peut etre aussi que j’en avais besoin pour les workflows…)

‘Pis, un Agents, c’est quoi ? hein ? bah un prompt système, des outils et des prompts spécifiques pour les tâches ! Donc ça aussi vous en avez une librairie !

Les prompts et les agents peuvent s’intégrer dans les workflows (duh, ils étaient faits pour ça !) mais vous avez aussi des étapes de “transformation”/exécution de code utilisateur/“prompt personnalisé” pour faciliter le transit !

Comme vous l’avez peut-être deviné, si j’ai une forme d’exécution de code pour les workflows, Est ce que je pourrais t’y donc pas faire tourner le code généré par l’IA, hein ? Eeeeh bha SI ! En Python ou JavaScript Et même que si vous ête un dinguo, vous pouvez faire tourner le js en mode “unsafe” (eval et yolo XD) du coup ca peut produire des trucs (comme ce one shot threejs scroll shooter ) que vous pouvez exporter en 1 clic (le template est moche mais je vais y travailler !)

Afin de n’pas completement obliterer le context, tous ces jolis blocs d’UI peuvent être “activés” (plutôt suggérés ^^) en utilisant des règles. Evidement, vous pouvez ajouter vos règles a vous ! Et meme que vous avez un bouton pour demander a l’IA de les choisir pour vous pour votre prompt actuel !

Bien sûr, vous avez les habituels regen (avec un modèle différent si le coeur vous en dis) et forking, mais vous pouvez aussi modifier une réponse a la main pour dégager l’inutile. D’ailleur, Les blocs de code sont aussi modifiable avec la coloration syntaxique pour les langages les plus courants, (mais pas d’auto-complétion ou autre truc de bogoss, on va pas poussez mémé dans les orties !).

Pour couronner le tout, vous pouvez organiser des courses d’IA avec un nombre illimité de participants (ca dependra de la profondeur de votre portefeuille :P). C’est cool pour faire des benchmarks ou quand on veut voir laquelle des machines prendra notre place en premier… J’ai même fait un petit outil qui prend une conversation de course exportée et qui crée un mini site de benchmark (plus ciblé sur le bloc d’exécution JS pour l’instant https://dimitrigilbert.github.io/racebench/scroller/index.html pour le “jeu” d’avant)

J’oublie certainement quelques bricoles, mais vous avez compris l’essentiel ^^

La version hébergée est sur les pages GitHub et il n’y a pas de tracking, pas de compte ! Vous apportez vos propres clés API ! Vous ne pourrez probablement pas utiliser la version hébergée pour votre LLM local à cause des restrictions https/http, mais comme je l’ai dit, vous pouvez télécharger https://github.com/DimitriGilbert/LiteChat/releases et héberger avec un simple serveur HTTP. Vous avez même des versions localisées pour le français, l’italien, l’allemand et l’espagnol. Une petite playlist (très incomplète) de tutoriels si vous vous sentez un peu perdu https://www.youtube.com/playlist?list=PL5Doe56gCsNRdNyfetOYPQw_JkPHO3XVh

J’espère que vous apprécierez et les commentaires constructifs sont grandement appréciés :D0:{"P":null,"b":"NRr8LmFrHuALZKXDD2S1C","p":"","c":["",""],"i":false,"f":[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",["$","$1","c",{"children":[[["$","link","0",{"rel":"stylesheet","href":"/_next/static/css/50152c3edddaf6a5.css","precedence":"next","crossOrigin":"$undefined","nonce":"$undefined"}]],["$","html",null,{"lang":"en","suppressHydrationWarning":true,"children":[["$","head",null,{"children":["$","script",null,{"src":"https://cdn.counter.dev/script.js","data-id":"154c6878-7558-4eff-90f9-bd4904015df1","data-utcoffset":"1","async":true}]}],["$","body",null,{"className":"__className_f367f3","children":["$","$L2",null,{"attribute":"class","defaultTheme":"dark","enableSystem":true,"disableTransitionOnChange":true,"children":[["$","$L3",null,{}],["$","main",null,{"children":["$","$L4",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L5",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[[],[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":404}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]]],"forbidden":"$undefined","unauthorized":"$undefined"}]}]]}]}]]}]]}],{"children":["__PAGE__",["$","$1","c",{"children":[["$","$L6",null,{"projects":[{"id":"LiteChat","name":"LiteChat","description":"A modern, local first AI chat app for your browser.","image":"/images/litechat/project.jpg","repo":"https://github.com/DimitriGilbert/LiteChat","site":"https://litechat.dbuild.dev","tags":["pwa","ai","chat-application","agents","llm","local-llm"]},{"id":"FormEdible","name":"FormEdible","description":"A React hook for creating schema-driven forms with TanStack Form and shadcn/ui components.","image":"/images/FormEdible/project.jpg","repo":"https://github.com/DimitriGilbert/FormEdible","site":"https://dimitrigilbert.github.io/Formedible/","tags":["Shadcn","Registry","form","hook","react","typescript","zod"]},{"id":"cn-registry","name":"cn-registry.dev","description":"A hub for Shadcn components and tools.","image":"/images/cn-registry.dev/project.jpg","repo":"https://github.com/DimitriGilbert/cn-registry.dev","site":"https://cn-registry.dev","tags":["Shadcn","Registry"]},{"id":"parseArger","name":"parseArger","description":"Standalone bash argument parsing code generator.","image":"/images/parsearger/project.jpg","repo":"https://github.com/DimitriGilbert/parseArger","site":"https://dimitrigilbert.github.io/parseArger/","tags":[]},{"id":"TerMinable","name":"TerMinable","description":"A demonstration terminal for you projects (or mine).","image":"/images/terminable/project.jpg","repo":"https://github.com/DimitriGilbert/TerMinable","site":"https://terminable.dbuild.dev/","tags":["Shadcn","Registry","Terminal","React","Typescript"]},{"id":"sshm0","name":"sshm0","description":"A simple CLI ssh connection manager","image":"/images/sshm0/project.jpg","repo":"https://github.com/DimitriGilbert/sshm0","site":"https://github.com/DimitriGilbert/sshm0","tags":["ssh","bash","cli","parseArger"]},{"id":"AI-gents","name":"AI-gents","description":"AI-gents. A simple format for AI agents.","image":"/images/ai-gents/project.jpg","repo":"https://github.com/DimitriGilbert/AI-gents","site":"ai-gents.dbuild.dev/","tags":["bash","cli","parseArger","ai","agents"]},{"id":"StationIO-Station","name":"StationIO","description":"Arduino framework-ish that handle the basics (wifi, ota, etc.)","image":"/placeholder.svg?height=400&width=600","repo":"https://github.com/DimitriGilbert/StationIO-Station","site":"dimitrigilbert.github.io/StationIO-Station/","tags":["arduino","esp8266","esp32"]},{"id":"RaceBench","name":"RaceBench","description":"Benchmarking LLMs on real JavaScript code generation tasks with executable results.","image":"/placeholder.svg?height=400&width=600","repo":"https://github.com/DimitriGilbert/racebench","site":"https://dimitrigilbert.github.io/racebench/scroller/index.html","tags":["benchmark","llm","ai","testing","javascript","three.js"]},{"id":"Task-O-Matic","name":"Task-O-Matic","description":"AI-powered task management system transforming chaotic ideas into structured, executable task lists.","image":"/placeholder.svg?height=400&width=600","repo":"https://github.com/DimitriGilbert/task-o-matic","site":"https://github.com/DimitriGilbert/task-o-matic","tags":["ai","task-management","cli","productivity","typescript","bun"]},{"id":"Sprynge","name":"Sprynge","description":"Community-driven help & earn platform with unique reciprocity mechanic: help 2 to unlock posting.","image":"/placeholder.svg?height=400&width=600","repo":"https://github.com/DimitriGilbert/sprynge-next","site":"https://github.com/DimitriGilbert/sprynge-next","tags":["community","help","nextjs","convex","real-time","gamification"]},{"id":"git-moar","name":"git-moar","description":"Advanced Git repository analytics and reporting CLI tool with beautiful HTML reports and visualizations.","image":"/placeholder.svg?height=400&width=600","repo":"https://github.com/DimitriGilbert/git-report","site":"https://github.com/DimitriGilbert/git-report","tags":["git","analytics","cli","visualization","javascript","nodejs"]}],"projectTags":["React","Registry","Shadcn","Terminal","Typescript","agents","ai","analytics","arduino","bash","benchmark","bun","chat-application","cli","community","convex","esp32","esp8266","form","gamification","git","help","hook","javascript","llm","local-llm","nextjs","nodejs","parseArger","productivity","pwa","react","real-time","ssh","task-management","testing","three.js","typescript","visualization","zod"],"recentPosts":[{"slug":"black-hole-from-ralph-to-eric","title":"From Ralph to Eric","description":"Everyone is going crazy about Ralph loop, and they are cool, but I think we need to upgrade to concept to an Eric loop !","date":"$D2026-01-16T23:01:00.000Z","category":"General","tags":["AI","Ralph lopp","Eric loop"],"content":"$7","readTime":15,"toc":[{"level":2,"title":"The Eric Loop","id":"the-eric-loop"},{"level":2,"title":"But, Why... ?","id":"but-why"},{"level":2,"title":"What would it look like ?","id":"what-would-it-look-like"},{"level":3,"title":"Task-o-matic","id":"task-o-matic"},{"level":3,"title":"Let's get this rolling","id":"lets-get-this-rolling"},{"level":4,"title":"Initialisation and bootstrapping","id":"initialisation-and-bootstrapping"},{"level":4,"title":"Document the requirements of your project","id":"document-the-requirements-of-your-project"},{"level":4,"title":"Petrol is not the only thing that needs refining !","id":"petrol-is-not-the-only-thing-that-needs-refining"},{"level":4,"title":"Touching up and go","id":"touching-up-and-go"},{"level":4,"title":"AGENTS.md","id":"agentsmd"},{"level":4,"title":"Time to let Eric loose...","id":"time-to-let-eric-loose"},{"level":3,"title":"What's the result","id":"whats-the-result"},{"level":2,"title":"What do you think ? Where do we go from here ?","id":"what-do-you-think-where-do-we-go-from-here"}],"directory":"Black hole/From ralph to Eric","relativePath":"Black hole/From ralph to Eric/index.md","filePath":"/home/didi/workspace/Code/dbuild.io/apps/web/content/blog/Black hole/From ralph to Eric/index.md","isCategory":false,"ogImage":"/images/blog/blackhole/from_ralph_to_eric/Eric_saw_Ralph.webp"},{"slug":"black-hole-passer-de-ralph-a-eric","title":"Passer de Ralph a Eric","description":"Tout le monde ne parle que de la 'Ralph loop', et le principe est cool, mais je pense qu'on peut faire mieux grace au concept de la Boucle a Eric !","date":"$D2026-01-16T23:00:00.000Z","category":"General","tags":["AI","Ralph lopp","Eric loop"],"content":"$8","readTime":16,"toc":[{"level":2,"title":"La boucle Eric","id":"la-boucle-eric"},{"level":2,"title":"Mais, Pourquoi... ?","id":"mais-pourquoi"},{"level":2,"title":"A quoi ça ressemblerait ?","id":"a-quoi-a-ressemblerait"},{"level":3,"title":"Task-o-matic","id":"task-o-matic"},{"level":3,"title":"Allons-y","id":"allons-y"},{"level":4,"title":"Initialisation et bootstrap","id":"initialisation-et-bootstrap"},{"level":4,"title":"Documenter les requis de votre projet","id":"documenter-les-requis-de-votre-projet"},{"level":4,"title":"L'essence n'est pas la seule chose qui doit être raffinée !","id":"lessence-nest-pas-la-seule-chose-qui-doit-tre-raffine"},{"level":4,"title":"Les petites retouches et c'est parti","id":"les-petites-retouches-et-cest-parti"},{"level":4,"title":"AGENTS.md","id":"agentsmd"},{"level":4,"title":"Et maintenant, on fait rouler Eric...","id":"et-maintenant-on-fait-rouler-eric"},{"level":3,"title":"Résultat","id":"rsultat"},{"level":2,"title":"Vous en pensez quoi ? On va où après ?","id":"vous-en-pensez-quoi-on-va-o-aprs"}],"directory":"Black hole/Passer de Ralph a Eric","relativePath":"Black hole/Passer de Ralph a Eric/index.md","filePath":"/home/didi/workspace/Code/dbuild.io/apps/web/content/blog/Black hole/Passer de Ralph a Eric/index.md","isCategory":false,"ogImage":"/images/blog/blackhole/from_ralph_to_eric/Eric_saw_Ralph.webp"},{"slug":"projects-cn-registry-devlog-1-the-illusion-of-victory","title":"cn-registry devlog 1 - The illusion of victory","description":"Follow me on a journey of failure and foolishness, en route to master the current crop of AI.","date":"$D2025-07-24T14:00:17.000Z","category":"General","tags":["shadcn","devlog","cn-registry"],"content":"$9","readTime":12,"toc":[{"level":2,"title":"Why ?","id":"why"},{"level":2,"title":"What is it already ?","id":"what-is-it-already"},{"level":2,"title":"The process","id":"the-process"},{"level":3,"title":"The Idea","id":"the-idea"},{"level":3,"title":"Initial plan","id":"initial-plan"},{"level":3,"title":"Start proompting","id":"start-proompting"},{"level":3,"title":"Select your stack","id":"select-your-stack"},{"level":3,"title":"Let the music start !","id":"let-the-music-start"},{"level":3,"title":"Broken string and other misadventures...","id":"broken-string-and-other-misadventures"},{"level":3,"title":"more, More, MOOOOAR","id":"more-more-mooooar"},{"level":3,"title":"Tidy up and go forward","id":"tidy-up-and-go-forward"},{"level":3,"title":"One day at a time","id":"one-day-at-a-time"}],"directory":"Projects/cn-registry/devlog 1 : The Illusion of Victory","relativePath":"Projects/cn-registry/devlog 1 : The Illusion of Victory/index.md","filePath":"/home/didi/workspace/Code/dbuild.io/apps/web/content/blog/Projects/cn-registry/devlog 1 : The Illusion of Victory/index.md","isCategory":false,"ogImage":"$undefined"},{"slug":"projects-cn-registry-devlog-1-une-illusion-de-victoire","title":"cn-registry devlog 1 -Une illusion de victoire","description":"Suivez-moi dans un voyage d'échecs et de folie, en route pour maîtriser la nouvelle génération d'IA.","date":"$D2025-07-24T14:00:17.000Z","category":"General","tags":["shadcn","devlog","cn-registry"],"content":"$a","readTime":13,"toc":[{"level":2,"title":"Pourquoi ?","id":"pourquoi"},{"level":2,"title":"Qu'est-ce que c'est déjà ?","id":"quest-ce-que-cest-dj"},{"level":2,"title":"Le processus","id":"le-processus"},{"level":3,"title":"L'idée","id":"lide"},{"level":3,"title":"Plan initial","id":"plan-initial"},{"level":3,"title":"A vos marques, pret, proomptez !","id":"a-vos-marques-pret-proomptez"},{"level":3,"title":"Sélectionnez votre stack","id":"slectionnez-votre-stack"},{"level":3,"title":"Laissez la musique commencer !","id":"laissez-la-musique-commencer"},{"level":3,"title":"C'est Bestel, il a mis la cassette et puis pouf !","id":"cest-bestel-il-a-mis-la-cassette-et-puis-pouf"},{"level":3,"title":"encore, Encore, ENCOOORE","id":"encore-encore-encooore"},{"level":3,"title":"Vous en avez mare de ces details ? et bhe on va vous en débarrasser","id":"vous-en-avez-mare-de-ces-details-et-bhe-on-va-vous-en-dbarrasser"},{"level":3,"title":"Un jour à la fois","id":"un-jour-la-fois"}],"directory":"Projects/cn-registry/devlog 1 : Une illusion de victoire","relativePath":"Projects/cn-registry/devlog 1 : Une illusion de victoire/index.md","filePath":"/home/didi/workspace/Code/dbuild.io/apps/web/content/blog/Projects/cn-registry/devlog 1 : Une illusion de victoire/index.md","isCategory":false,"ogImage":"$undefined"},{"slug":"projects-litechat-litechat-a-local-first-and-self-hostable-ai-chat-app-for-power-user","title":"LiteChat - A local first and self hostable AI chat app for power user","description":"A smallish presentation of my project LiteChat !","date":"$D2025-07-04T10:40:17.000Z","category":"General","tags":["ai","chat","local","server"],"content":"$b","readTime":4,"toc":[],"directory":"Projects/LiteChat/LiteChat : A local first and self hostable AI chat app for power user","relativePath":"Projects/LiteChat/LiteChat : A local first and self hostable AI chat app for power user/index.md","filePath":"/home/didi/workspace/Code/dbuild.io/apps/web/content/blog/Projects/LiteChat/LiteChat : A local first and self hostable AI chat app for power user/index.md","isCategory":false,"ogImage":"$undefined"},{"slug":"projects-litechat-litechat-un-chat-ia-local-first-auto-hebergeable-sur-un-server-http","title":"LiteChat - Un chat IA local first, auto hebergeable sur un server HTTP","description":"Une petite présentation de mon projet LiteChat, en Français dans le texte !","date":"$D2025-07-04T10:39:17.000Z","category":"General","tags":["ai","chat","local","server"],"content":"$c","readTime":5,"toc":[],"directory":"Projects/LiteChat/LiteChat : Un chat IA local first, auto hebergeable sur un server HTTP","relativePath":"Projects/LiteChat/LiteChat : Un chat IA local first, auto hebergeable sur un server HTTP/index.md","filePath":"/home/didi/workspace/Code/dbuild.io/apps/web/content/blog/Projects/LiteChat/LiteChat : Un chat IA local first, auto hebergeable sur un server HTTP/index.md","isCategory":false,"ogImage":"$undefined"}],"blogTags":["AI","Eric loop","Ralph lopp","ai","analytics","bash","benchmark","chat","cli","cn-registry","devlog","form","french","git","homelab","llm","local","mdd","parseArger","parsearger","productivity","react","rpi","scripting","server","shadcn","tanstack","task-management","task-o-matic","terminal","testing","tutorial","typescript","visualization","zod"],"totalPosts":22}],null,["$","$Ld",null,{"children":"$Le"}]]}],{},null,false]},null,false],["$","$1","h",{"children":[null,["$","$1","0LQdaWV3JfeEOH6ae6rRs",{"children":[["$","$Lf",null,{"children":"$L10"}],["$","$L11",null,{"children":"$L12"}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}]]}],false]],"m":"$undefined","G":["$13","$undefined"],"s":false,"S":true}
12:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]
10:[["$","meta","0",{"charSet":"utf-8"}],["$","title","1",{"children":"Dbuild.dev"}],["$","meta","2",{"name":"description","content":"Dbuild.dev is a portfolio and blog showcasing projects and insights"}],["$","link","3",{"rel":"manifest","href":"/manifest.webmanifest","crossOrigin":"$undefined"}],["$","meta","4",{"name":"robots","content":"index, follow"}],["$","meta","5",{"name":"googlebot","content":"index, follow"}],["$","meta","6",{"property":"og:title","content":"Dbuild.dev"}],["$","meta","7",{"property":"og:description","content":"Dbuild.dev is a portfolio and blog showcasing projects and insights"}],["$","meta","8",{"property":"og:url","content":"https://dbuild.dev/"}],["$","meta","9",{"property":"og:site_name","content":"Dbuild.dev"}],["$","meta","10",{"property":"og:locale","content":"en_US"}],["$","meta","11",{"property":"og:image","content":"https://dbuild.dev/og-image.jpg"}],["$","meta","12",{"property":"og:image:width","content":"1200"}],["$","meta","13",{"property":"og:image:height","content":"630"}],["$","meta","14",{"property":"og:image:alt","content":"Dbuild.dev - Portfolio and Blog"}],["$","meta","15",{"property":"og:type","content":"website"}],["$","meta","16",{"name":"twitter:card","content":"summary_large_image"}],["$","meta","17",{"name":"twitter:title","content":"Dbuild.dev"}],["$","meta","18",{"name":"twitter:description","content":"Dbuild.dev is a portfolio and blog showcasing projects and insights"}],["$","meta","19",{"name":"twitter:image","content":"https://dbuild.dev/og-image.jpg"}],["$","link","20",{"rel":"icon","href":"/favicon.ico","type":"image/x-icon","sizes":"32x32"}]]
e:null
